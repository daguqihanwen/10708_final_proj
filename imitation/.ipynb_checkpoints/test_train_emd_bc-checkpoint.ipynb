{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3e9ddaa-b484-404b-8691-e8605a32f9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jianrenw/carl/research/dev/PlasticineLab\n",
      "[Taichi] mode=release\n",
      "[Taichi] preparing sandbox at /tmp/taichi-ayrjthpt\n",
      "[Taichi] version 0.7.26, llvm 10.0.0, commit e37bdb5e, linux, python 3.8.11\n",
      "[I 10/27/21 20:02:53.635 1358824] [shell.py:_shell_pop_print@35] Graphical python shell detected, using wrapped sys.stdout\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '~/carl/research/dev/PlasticineLab'\n",
    "%pwd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import taichi as ti\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from plb.utils.visualization_utils import save_rgb\n",
    "from plb.algorithms.bc.bc_agent import Agent\n",
    "from imitation.imitation_buffer import ImitationReplayBuffer, filter_buffer_nan\n",
    "from imitation.utils import aggregate_traj_info\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "from chester import logger\n",
    "#\n",
    "from plb.envs import make \n",
    "from plb.envs.mp_wrapper import make_mp_envs\n",
    "from imitation.utils import load_target_info\n",
    "from imitation.utils import visualize_trajs\n",
    "from imitation.eval_helper import eval_skills, eval_vae, eval_plan\n",
    "import wandb\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def get_args(cmd=False):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--env_name', type=str, default='Roll-v1')\n",
    "    parser.add_argument('--exp_prefix', type=str, default='1026_Roll_BC_Image')\n",
    "    parser.add_argument('--num_env', type=int, default=1)  # Number of parallel environment\n",
    "    parser.add_argument('--algo', type=str, default='imitation')\n",
    "    parser.add_argument('--dataset_name', type=str, default='tmp')\n",
    "    parser.add_argument(\"--seed\", type=int, default=100)\n",
    "    parser.add_argument(\"--gd_num_steps\", type=int, default=50, help=\"steps for the gradient descent(gd) expert\")\n",
    "\n",
    "    # differentiable physics parameters\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.02)  # For the solver\n",
    "    parser.add_argument(\"--softness\", type=float, default=666.)\n",
    "    parser.add_argument(\"--optim\", type=str, default='Adam', choices=['Adam', 'Momentum'])\n",
    "    parser.add_argument(\"--num_trajs\", type=int, default=20)  # Number of demonstration trajectories\n",
    "    parser.add_argument(\"--energy_weight\", type=float, default=0.)\n",
    "    parser.add_argument(\"--vel_loss_weight\", type=float, default=0.)\n",
    "\n",
    "    # Train\n",
    "    parser.add_argument(\"--il_num_epoch\", type=int, default=5000)\n",
    "    parser.add_argument(\"--il_lr\", type=float, default=1e-3)\n",
    "    parser.add_argument(\"--il_eval_freq\", type=int, default=10)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=128)\n",
    "    parser.add_argument(\"--step_per_epoch\", type=int, default=500)\n",
    "    parser.add_argument(\"--step_warmup\", type=int, default=2000)\n",
    "    parser.add_argument(\"--hindsight_goal_ratio\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--debug_overfit_test\", type=bool, default=False)\n",
    "    parser.add_argument(\"--obs_noise\", type=float, default=0.05)\n",
    "    parser.add_argument(\"--resume_path\", default=None)\n",
    "    parser.add_argument(\"--num_tools\", type=int, default=1)\n",
    "\n",
    "    # Architecture\n",
    "    parser.add_argument(\"--frame_stack\", type=int, default=1)\n",
    "    parser.add_argument(\"--image_dim\", type=int, default=64)\n",
    "    parser.add_argument(\"--img_mode\", type=str, default='rgb')\n",
    "    parser.add_argument(\"--pos_ratio\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--pos_reset_ratio\", type=float, default=0.2)  # 20% of the positive goals will come from the reset motion\n",
    "    parser.add_argument(\"--z_dim\", type=int, default=32)  # Maybe try multiple values\n",
    "    parser.add_argument(\"--actor_feature_dim\", type=int, default=128)\n",
    "    parser.add_argument(\"--encoder_beta\", type=float, default=10.)\n",
    "    parser.add_argument(\"--bin_succ\", type=bool, default=False)\n",
    "\n",
    "    # Plan\n",
    "    parser.add_argument(\"--adam_sample\", type=int, default=400)\n",
    "    parser.add_argument(\"--adam_iter\", type=int, default=3000)\n",
    "    parser.add_argument(\"--adam_lr\", type=float, default=5e-2)\n",
    "    parser.add_argument(\"--min_zlogl\", type=float, default=-30)\n",
    "    parser.add_argument(\"--save_goal_his\", type=bool, default=False)\n",
    "    parser.add_argument(\"--plan_step\", type=int, default=2)\n",
    "\n",
    "    if cmd:\n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(\"\")\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def eval_traj(traj_ids, args, buffer, env, agent, np_target_imgs, save_name, visualize=False):\n",
    "    horizon = 50\n",
    "    trajs = []\n",
    "    demo_obses = []\n",
    "    for traj_id in traj_ids:\n",
    "        init_v = int(buffer.buffer['init_v'][traj_id * horizon])\n",
    "        target_v = int(buffer.buffer['target_v'][traj_id * horizon])\n",
    "        reset_key = {'init_v': init_v, 'target_v': target_v}\n",
    "        tid = buffer.get_tid(buffer.buffer['action_mask'][traj_id * horizon])\n",
    "        traj = sample_traj(env, agent, reset_key, tid)\n",
    "        \n",
    "        demo_obs = buffer.buffer['obses'][traj_id * horizon: traj_id * horizon + horizon]\n",
    "        demo_obses.append(demo_obs)\n",
    "        traj['target_img'] = demo_obs[-1]\n",
    "        # demo_target_ious.append(buffer.buffer['target_ious'][traj_id * horizon + horizon - 1])\n",
    "        print(f'tid: {tid}, traj_id: {traj_id}, reward: {np.sum(traj[\"rewards\"])}')\n",
    "        trajs.append(traj)\n",
    "    demo_obses = np.array(demo_obses)\n",
    "\n",
    "    # agent_ious = np.array([traj['target_ious'][-1, 0] for traj in trajs])\n",
    "    # demo_target_ious = np.array(demo_target_ious)\n",
    "    # logger.log('Agent ious: {}, Demo ious: {}'.format(np.mean(agent_ious), np.mean(demo_target_ious)))\n",
    "    if visualize:\n",
    "        visualize_trajs(trajs, 10, key='info_emds', save_name=os.path.join(logger.get_dir(), save_name),\n",
    "                        vis_target=True, demo_obses=demo_obses[:, :, :, :, :3])\n",
    "    # info = {'agent_iou': np.mean(agent_ious), 'demo_iou': np.mean(demo_target_ious)}\n",
    "    \n",
    "    info = {'eval_final_normalized_performance': traj['info_final_normalized_performance'], \n",
    "    'eval_avg_normalized_performance': np.mean(traj['info_normalized_performance'])}\n",
    "    return info\n",
    "\n",
    "\n",
    "def prepare_agent_env(args):\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_task(arg_vv, log_dir, exp_name):  # Chester launch\n",
    "    args = get_args(cmd=False)\n",
    "\n",
    "    args.__dict__.update(**arg_vv)\n",
    "\n",
    "    set_random_seed(args.seed)\n",
    "\n",
    "    # # Configure logger\n",
    "    logger.configure(dir=log_dir, exp_name=exp_name)\n",
    "    log_dir = logger.get_dir()\n",
    "    assert log_dir is not None\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    # # Dump parameters\n",
    "    with open(os.path.join(logger.get_dir(), 'variant.json'), 'w') as f:\n",
    "        json.dump(args.__dict__, f, indent=2, sort_keys=True)\n",
    "\n",
    "    # Need to make the environment before moving tensor to torch\n",
    "    obs_channel = len(args.img_mode) * args.frame_stack\n",
    "    img_obs_shape = (args.image_dim, args.image_dim, obs_channel)\n",
    "    env = make_mp_envs(args.env_name, args.num_env, args.seed)\n",
    "\n",
    "    args.cached_state_path = env.getattr('cfg.cached_state_path', 0)\n",
    "    print(args.cached_state_path)\n",
    "    action_dim = env.getattr('taichi_env.primitives.action_dim')[0]\n",
    "\n",
    "    # Load buffer\n",
    "    device = 'cuda'\n",
    "    buffer = ImitationReplayBuffer(args)\n",
    "    buffer.load(args.dataset_path)\n",
    "    filter_buffer_nan(buffer)\n",
    "    print(\"buffer size:\", buffer.cur_size)\n",
    "\n",
    "    buffer.generate_train_eval_split()\n",
    "    target_info = load_target_info(args, device)\n",
    "    buffer.__dict__.update(**target_info)\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    # # ----------preparation done------------------\n",
    "    agent = Agent(args, None, img_obs_shape, action_dim, num_tools=1, device=device)\n",
    "    if args.resume_path is not None:\n",
    "        agent.load(args.resume_path)\n",
    "\n",
    "    total_steps = 0\n",
    "    eval_idxes = np.random.permutation(buffer.eval_traj_idx)[:min(30, len(buffer.eval_traj_idx))]\n",
    "    print(\"eval_idxes:\", eval_idxes)\n",
    "    for epoch in range(args.il_num_epoch):\n",
    "        train_infos = []\n",
    "        data_batch = buffer.sample_tool_transitions_bc([np.random.permutation([i for i in range(50)]),], epoch, device)\n",
    "        train_info = agent.train(data_batch)\n",
    "        train_infos.append(train_info)\n",
    "        if epoch % args.il_eval_freq == 0:\n",
    "            # Log training info\n",
    "            train_infos = aggregate_traj_info(train_infos, prefix=None)\n",
    "\n",
    "\n",
    "            # evaluate\n",
    "            if epoch % (args.il_eval_freq*2) == 0:\n",
    "                # plan_info = eval_plan(args, env, agent, epoch)\n",
    "                plan_info = eval_traj([0], args, buffer, env, agent, buffer.np_target_imgs, f'visual_{epoch}.gif',visualize=True)\n",
    "            else:\n",
    "                plan_info = eval_traj([0], args, buffer, env, agent, buffer.np_target_imgs, f'visual_{epoch}.gif',visualize=False)\n",
    "\n",
    "            # Logging\n",
    "            logger.record_tabular('epoch', epoch)\n",
    "            logger.record_tabular('total steps', total_steps)\n",
    "            all_info = {}\n",
    "            all_info.update(**train_infos)\n",
    "            all_info.update(**plan_info)\n",
    "            all_info.update({'epoch': epoch, 'total steps': total_steps})\n",
    "            for key, val in all_info.items():\n",
    "                logger.record_tabular(key, val)\n",
    "            logger.dump_tabular()\n",
    "\n",
    "            # Save model\n",
    "            if epoch % (args.il_eval_freq * 2) == 0:\n",
    "                agent.save(os.path.join(logger.get_dir(), f'agent_{epoch}.ckpt'))\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf973585-d2c7-4140-b630-4b1a386377fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from plb.algorithms.bc.bc_agent import Agent as BCAgent\n",
    "from imitation.utils import img_to_tensor, to_action_mask\n",
    "from plb.envs.mp_wrapper import SubprocVecEnv\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import os\n",
    "from chester import logger\n",
    "device = 'cuda'\n",
    "def sample_traj(env, agent, reset_key, tid, action_mask=None, action_sequence=None, log_succ_score=False, reset_primitive=False, num_moves=1, init='zero'):\n",
    "    \"\"\"Compute ious: pairwise iou between each pair of timesteps. \"\"\"\n",
    "    assert agent.args.num_env == 1\n",
    "    states, obses, actions, rewards, succs, scores =[],  [], [], [], [0.], [0.]  # Append 0 for the first frame for succs and scores\n",
    "    if action_sequence is None and action_mask is None:\n",
    "        if tid == 0:\n",
    "            action_mask = to_action_mask(env, [1, 0])\n",
    "        else:\n",
    "            action_mask = to_action_mask(env, [0, 1])\n",
    "\n",
    "    if isinstance(env, SubprocVecEnv):\n",
    "        if reset_key is not None:\n",
    "            state = env.reset([reset_key])[0]\n",
    "        obs = env.render(mode='rgb')[0]  # rgbd observation\n",
    "    else:\n",
    "        if reset_key is not None:\n",
    "            state = env.reset(**reset_key)\n",
    "        obs = env.render(mode='rgb')  # rgbd observation\n",
    "    \n",
    "    env.getfunc(\"taichi_env.load_target_x\", 0, [{'path':'data/debug/target_expert.npy'}])\n",
    "    \n",
    "    if reset_key is not None:\n",
    "        states.append(state)\n",
    "        obses.append(obs)\n",
    "    T = 50\n",
    "    total_r = 0\n",
    "\n",
    "    total_time = 0\n",
    "    agent_time = 0\n",
    "    env_time = 0\n",
    "    st_time = time.time()\n",
    "    if isinstance(agent, BCAgent): # learner\n",
    "        action_dim = env.getattr(\"taichi_env.primitives.action_dim\", 0)\n",
    "        frame_stack = agent.args.frame_stack\n",
    "        _, _, _, mp_info = env.step([np.zeros(action_dim)])\n",
    "        if reset_primitive:\n",
    "            primitive_state = env.getfunc('get_primitive_state', 0)\n",
    "        if reset_key is not None:\n",
    "            infos = [mp_info[0]]\n",
    "        else:\n",
    "            infos = []\n",
    "        # mass_grids.append(info['mass_grid'])\n",
    "        stack_obs = img_to_tensor(np.array(obs)[None], mode=agent.args.img_mode).to(agent.device)  # stack_obs shape: [1, 4, 64, 64]\n",
    "        target_img = img_to_tensor(np.array(env.getattr('target_img', 0))[None], mode=agent.args.img_mode).to(agent.device)\n",
    "        C = stack_obs.shape[1]\n",
    "        stack_obs = stack_obs.repeat([1, frame_stack, 1, 1])\n",
    "        with torch.no_grad():\n",
    "            for i in range(T):\n",
    "                t1 = time.time()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    action, done = agent.act(stack_obs, target_img, tid)\n",
    "                    action = action[0].detach().cpu().numpy()\n",
    "                    done = done[0].detach().cpu().numpy()\n",
    "                obs_tensor = img_to_tensor(np.array(obs)[None], mode=agent.args.img_mode).to(agent.device)\n",
    "                stack_obs = torch.cat([stack_obs, obs_tensor], dim=1)[:, -frame_stack * C:]\n",
    "                if np.round(done).astype(int) == 1 and agent.terminate_early:\n",
    "                    break\n",
    "                t2 = time.time()\n",
    "                mp_next_state, mp_reward, _, mp_info = env.step([action])\n",
    "                next_state, reward, info = mp_next_state[0], mp_reward[0], mp_info[0]\n",
    "\n",
    "                infos.append(info)\n",
    "                t3 = time.time()\n",
    "\n",
    "                agent_time += t2 - t1\n",
    "                env_time += t3 - t2\n",
    "\n",
    "                actions.append(action)\n",
    "                states.append(next_state)\n",
    "                obs = env.render(mode='rgb')[0]\n",
    "                obses.append(obs)\n",
    "                total_r += reward\n",
    "                rewards.append(reward)\n",
    "                if log_succ_score:\n",
    "                    succs.append(succ)\n",
    "                    scores.append(score)\n",
    "        target_img = np.array(env.getattr('target_img', 0))\n",
    "\n",
    "    emds = np.array([info['info_emd'] for info in infos])\n",
    "    if len(infos) > 0:\n",
    "        info_normalized_performance = np.array([info['info_normalized_performance'] for info in infos])\n",
    "        info_final_normalized_performance = info_normalized_performance[-1]\n",
    "    else:\n",
    "        info_normalized_performance = []\n",
    "        info_final_normalized_performance = None\n",
    "\n",
    "    total_time = time.time() - st_time\n",
    "    ret = {'states': np.array(states).astype(np.float32),\n",
    "           'obses': np.array(obses).astype(np.float32),\n",
    "           'actions': np.array(actions).astype(np.float32),\n",
    "           'target_img': target_img,\n",
    "           'rewards': np.array(rewards),\n",
    "           'info_rewards': np.array(rewards),\n",
    "           'info_emds': emds,\n",
    "           'info_final_normalized_performance': info_final_normalized_performance,\n",
    "           'info_normalized_performance': info_normalized_performance,\n",
    "           'info_total_r': total_r,\n",
    "           'info_total_time': total_time,\n",
    "           'info_agent_time': agent_time,\n",
    "           'info_env_time': env_time,\n",
    "           'action_mask': action_mask}\n",
    "    if log_succ_score:\n",
    "        ret['succs'] = np.array(succs)  # Should miss the first frame\n",
    "        ret['scores'] = np.array(scores)\n",
    "    if reset_key is not None:\n",
    "        ret.update(**reset_key)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b4ecd3-f8f4-4f57-91d7-451bc99fc7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./data/debug\n",
      "Setting pykeops dir to  ~/.cache/pykeops_2080/\n",
      "[Taichi] Starting on arch=cuda\n",
      "[Tina] version 0.1.1\n",
      "[Tina] Taichi properties hacked\n",
      "pimirives: num primitive: 2\n",
      "Building primitive\n",
      "action:\n",
      "  dim: 6\n",
      "  scale: (0.7, 0.005, 0.005, 0.005, 0.0, 0.0)\n",
      "collision_group: [0.0, 0.0, 0.0]\n",
      "color: (0.7568, 0.6039, 0.4196)\n",
      "friction: 0.9\n",
      "h: 0.3\n",
      "init_pos: (0.3, 0.25, 0.5)\n",
      "init_rot: (0.707, 0.707, 0.0, 0.0)\n",
      "lower_bound: (0.0, 0.1, 0.0)\n",
      "r: 0.03\n",
      "shape: RollingPinExt\n",
      "upper_bound: (1.0, 1.0, 1.0)\n",
      "variations: None\n",
      "Building primitive\n",
      "action:\n",
      "  dim: 0\n",
      "  scale: ()\n",
      "collision_group: [0.0, 0.0, 0.0]\n",
      "color: (0.5, 0.5, 0.5)\n",
      "friction: 5.0\n",
      "init_pos: (0.28, 0.04, 0.5)\n",
      "init_rot: (1.0, 0.0, 0.0, 0.0)\n",
      "lower_bound: (0.0, 0.0, 0.0)\n",
      "shape: Box\n",
      "size: (0.7, 0.02, 0.43)\n",
      "upper_bound: (1.0, 1.0, 1.0)\n",
      "variations: None\n",
      "Initialize Tina Renderer\n",
      "bake_size: 6  \n",
      "cam_center: (0.33, 0.1, 0.5)  \n",
      "cam_phi: -0.8  \n",
      "cam_radius: 0.8  \n",
      "cam_theta: 0.0  \n",
      "camera_pos: (0.5, 1.2, 4.0)  \n",
      "camera_rot: (0.2, 0)  \n",
      "dx: 0.006666666666666667  \n",
      "image_res: (128, 128)  \n",
      "light_direction: (0.0, 1.0, 1.0)  \n",
      "max_num_particles: 1000000  \n",
      "max_ray_depth: 2  \n",
      "mesh: False  \n",
      "name: tina  \n",
      "sdf_threshold: 0.20720000000000002  \n",
      "spp: 50  \n",
      "target_res: (64, 64, 64)  \n",
      "tina_img_res: 512  \n",
      "use_directional_light: True  \n",
      "use_roulette: False  \n",
      "voxel_res: (168, 168, 168)\n",
      "[Tina] Hint: MMB to orbit, Shift+MMB to pan, wheel to zoom\n",
      "Env reseting to: datasets/1006_Roll/target/target_24.npy, init v: 8, target v: 24\n",
      "emd after reset: 0.4252811670303345\n",
      "======================WARNING: contact loss mask not set================\n",
      "datasets/1006_Roll\n",
      "Loading dataset in data/debug/dataset.gz\n",
      "Loading dataset from data/debug/dataset.gz\n",
      "0 nan actions detected. making them zero.\n",
      "buffer size: 50\n",
      "class Agent: obs_shape:  (64, 64, 6)\n",
      "eval_idxes: [0]\n",
      "Env reseting to: datasets/1006_Roll/target/target_172.npy, init v: 47, target v: 172\n",
      "emd after reset: 0.4208467900753021\n",
      "======================WARNING: contact loss mask not set================\n",
      "tid: 0, traj_id: 0, reward: -1.5756811127066612\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (64,64,3) (50,64,3,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1358824/1800305994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'dataset_path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'data/debug/dataset.gz'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrun_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./data/debug'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1358824/3008733474.py\u001b[0m in \u001b[0;36mrun_task\u001b[0;34m(arg_vv, log_dir, exp_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mil_eval_freq\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# plan_info = eval_plan(args, env, agent, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mplan_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_target_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'visual_{epoch}.gif'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mplan_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_traj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_target_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'visual_{epoch}.gif'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1358824/3008733474.py\u001b[0m in \u001b[0;36meval_traj\u001b[0;34m(traj_ids, args, buffer, env, agent, np_target_imgs, save_name, visualize)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# logger.log('Agent ious: {}, Demo ious: {}'.format(np.mean(agent_ious), np.mean(demo_target_ious)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         visualize_trajs(trajs, 10, key='info_emds', save_name=os.path.join(logger.get_dir(), save_name),\n\u001b[0m\u001b[1;32m    121\u001b[0m                         vis_target=True, demo_obses=demo_obses[:, :, :, :, :3])\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# info = {'agent_iou': np.mean(agent_ious), 'demo_iou': np.mean(demo_target_ious)}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/carl/research/dev/PlasticineLab/imitation/utils.py\u001b[0m in \u001b[0;36mvisualize_trajs\u001b[0;34m(trajs, ncol, key, save_name, vis_target, demo_obses)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'obses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Do not change the input images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvis_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m                     \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.7\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtrajs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (64,64,3) (50,64,3,4) "
     ]
    }
   ],
   "source": [
    "vv = {\n",
    "    'task': 'train_policy',\n",
    "    'il_eval_freq': 1,\n",
    "    'num_epoch': 100,\n",
    "    'batch_size': 50,\n",
    "    'step_per_epoch':50,\n",
    "    'dataset_path': 'data/debug/dataset.gz'\n",
    "}\n",
    "run_task(vv, './data/debug', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c97724-f461-4e44-bc43-24da04119960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
