{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xingyu/Projects/PlasticineLab\n",
      "[Taichi] mode=release\n",
      "[Taichi] preparing sandbox at /tmp/taichi-6hzzblan\n",
      "[Taichi] version 0.7.15, llvm 10.0.0, commit cff542ce, linux, python 3.6.9\n",
      "[Taichi] Starting on arch=cuda\n",
      "Building primitive\n",
      "action:\n",
      "  dim: 6\n",
      "  scale: (0.7, 0.005, 0.005, 0.005, 0.0, 0.0)\n",
      "color: (0.8, 0.8, 0.8)\n",
      "friction: 0.9\n",
      "h: 0.3\n",
      "init_pos: (0.55, 0.2, 0.5)\n",
      "init_rot: (0.707, 0.707, 0.0, 0.0)\n",
      "lower_bound: (0.0, 0.09, 0.0)\n",
      "r: 0.03\n",
      "shape: RollingPinExt\n",
      "upper_bound: (1.0, 1.0, 1.0)\n",
      "variations: None\n",
      "Building primitive\n",
      "action:\n",
      "  dim: 6\n",
      "  scale: (0.015, 0.0, 0.0, 0.0, 0.0, 0.0)\n",
      "color: (0.8, 0.8, 0.8)\n",
      "friction: 0.9\n",
      "init_pos: (0.7, 0.1, 0.5)\n",
      "init_rot: (0.707, 0.707, 0.0, 0.0)\n",
      "lower_bound: (0.0, 0.0, 0.0)\n",
      "shape: Box\n",
      "size: (0.015, 0.15, 0.1)\n",
      "upper_bound: (1.0, 1.0, 1.0)\n",
      "variations: None\n",
      "{'init_pos': (0.5, 0.03576, 0.5), 'width': (0.2, 0.03575, 0.2), 'color': 100}\n",
      "Initialize Renderer\n",
      "bake_size: 6  \n",
      "camera_pos: (0.5, 0.4, 1.9)  \n",
      "camera_rot: (0.2, 0.0)  \n",
      "dx: 0.006666666666666667  \n",
      "image_res: (64, 64)  \n",
      "light_direction: (0.0, 1.0, 1.0)  \n",
      "max_num_particles: 1000000  \n",
      "max_ray_depth: 2  \n",
      "sdf_threshold: 0.20720000000000002  \n",
      "spp: 50  \n",
      "target_res: (64, 64, 64)  \n",
      "use_directional_light: True  \n",
      "use_roulette: False  \n",
      "voxel_res: (168, 168, 168)\n",
      "{'init_pos': (0.5, 0.03576, 0.5), 'width': (0.2, 0.03575, 0.2), 'color': 100}\n",
      "[Taichi] materializing...\n",
      "initialize: [0.5 0.4 1.9] [0.2 0. ]\n",
      "Version None. Skip target path\n",
      "{'init_pos': (0.5, 0.03576, 0.5), 'width': (0.2, 0.03575, 0.2), 'color': 100}\n",
      "initialize: [0.5 0.4 1.9] [0.2 0. ]\n",
      "class Agent: obs_shape:  (64, 64, 8)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd '/home/xingyu/Projects/PlasticineLab'\n",
    "%pwd\n",
    "\n",
    "import numpy as np\n",
    "from imitation.agent import Agent, sample_traj\n",
    "from plb.envs import make\n",
    "from imitation.train import get_args\n",
    "from plb.engine.taichi_env import TaichiEnv\n",
    "from plb.optimizer.solver import Solver\n",
    "from plb.algorithms.logger import Logger\n",
    "device = 'cuda'\n",
    "\n",
    "log_dir = './data/connect'\n",
    "args = get_args(\"\")\n",
    "\n",
    "obs_channel = len(args.img_mode)\n",
    "img_obs_shape = (args.image_dim, args.image_dim, obs_channel)\n",
    "\n",
    "\n",
    "env = make(args.env_name, nn=(args.algo == 'nn'), sdf_loss=args.sdf_loss,\n",
    "           density_loss=args.density_loss, contact_loss=args.contact_loss,\n",
    "           soft_contact_loss=args.soft_contact_loss, chamfer_loss=args.chamfer_loss)\n",
    "env.seed(args.seed)\n",
    "taichi_env: TaichiEnv = env.unwrapped.taichi_env\n",
    "T = env._max_episode_steps\n",
    "action_dim = taichi_env.primitives.action_dim\n",
    "\n",
    "plb_logger = Logger(log_dir)\n",
    "solver = Solver(taichi_env, plb_logger, None,\n",
    "                n_iters=(args.gd_num_steps + T - 1) // T, softness=args.softness, horizon=T,\n",
    "                **{\"optim.lr\": args.lr, \"optim.type\": args.optim, \"init_range\": 0.0001})\n",
    "agent = Agent(args, solver, img_obs_shape, action_dim, num_tools=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from imitation.utils import load_target_info\n",
    "target_info = load_target_info(args, device)\n",
    "np_target_imgs, target_imgs, np_target_mass_grids = target_info['np_target_imgs'], target_info['target_imgs'], target_info['np_target_mass_grids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Agent: obs_shape:  (64, 64, 8)\n",
      "Agent loaded from data/local/0722_PushSpread_train_fea_aug/0722_PushSpread_train_fea_aug_2021_07_23_12_12_33_0001/agent_50.ckpt\n",
      "Loading dataset in ./data/autobot/0718_PushSpread_train_fea/0718_PushSpread_train_fea/0718_PushSpread_train_fea_2021_07_20_11_34_11_0001/agent_dataset.gz\n",
      "Loading dataset from ./data/autobot/0718_PushSpread_train_fea/0718_PushSpread_train_fea/0718_PushSpread_train_fea_2021_07_20_11_34_11_0001/agent_dataset.gz\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from imitation.utils import img_to_np, write_number, img_to_tensor\n",
    "from plb.utils.visualization_utils import make_grid, save_rgb\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/home/xingyu/Projects/PlasticineLab/')\n",
    "\n",
    "# Trained on hindsight goals\n",
    "# agent_path = 'data/local/0629_PushSpread_train_fea/0629_PushSpread_train_fea_2021_07_01_11_34_12_0001/agent_350.ckpt'\n",
    "# Trained on real goals\n",
    "agent_path = 'data/local/0722_PushSpread_train_fea_aug/0722_PushSpread_train_fea_aug_2021_07_23_12_12_33_0001/agent_50.ckpt'\n",
    "agent = Agent(args, solver, img_obs_shape, action_dim, num_tools=2, device=device)\n",
    "agent.feas.eval()\n",
    "agent.load(agent_path)\n",
    "taichi_env.loss.set_target_update(False)\n",
    "\n",
    "agent_dataset = './data/autobot/0718_PushSpread_train_fea/0718_PushSpread_train_fea/0718_PushSpread_train_fea_2021_07_20_11_34_11_0001/agent_dataset.gz'\n",
    "from imitation.buffer import ReplayBuffer\n",
    "buffer = ReplayBuffer()\n",
    "buffer.load(agent_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import json\n",
    "from imitation.encoder.vae import VAE\n",
    "vae_dir = 'data/autobot/0729_vae/0729_vae/0729_vae_2021_07_29_15_53_40_0006/'\n",
    "vae_path = osp.join(vae_dir, 'encoder_95.pth')\n",
    "vae_vv_path = osp.join(vae_dir, 'variant.json')\n",
    "with open(vae_vv_path, 'r') as f:\n",
    "    vae_vv = json.load(f)\n",
    "vae = VAE(4)\n",
    "vae.load_state_dict(torch.load(vae_path))\n",
    "vae = vae.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test reconstruction of VAE\n",
    "reconst = vae.reconstr(target_imgs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_pos': (0.5, 0.03576, 0.5), 'width': (0.2, 0.03575, 0.2), 'color': 100}\n",
      "initialize: [0.5 0.4 1.9] [0.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "from imitation.compose_skills import plan, visualize_all_traj\n",
    "test_init_v = np.array([95, 95, 95, 91, 91, 91, ])\n",
    "test_target_v = np.array([25, 195, 128, 21, 191, 128])\n",
    "\n",
    "for init_v, target_v in zip(test_init_v, test_target_v):\n",
    "    plan_info = {'env':env, 'vae':vae,\n",
    "                 'init_v':init_v, 'target_v': target_v, 'num_sample': 100}\n",
    "    plan_info.update(**target_info)\n",
    "    imgs = plan(agent, plan_info, opt_mode='sample')\n",
    "    # best_traj, all_traj = plan(agent, plan_info, opt_mode='sample')\n",
    "    # img = visualize_all_traj(all_traj)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "cpu_imgs = img_to_np(imgs)\n",
    "grid_img = make_grid(cpu_imgs, ncol=20)\n",
    "save_rgb('./data/connect/vae_samples.png', grid_img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}